{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab19e736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ai_python_services.ai_agents import (\n",
    "    # LLM Agents\n",
    "    LLMAgent,\n",
    "    OpenAIAgent,\n",
    "    AnthropicAgent,\n",
    "    GoogleAgent,\n",
    "    # Audio-to-Text Agents\n",
    "    AudioToTextAgent,\n",
    "    OpenAITranscriptAgent,\n",
    "    GoogleTranscriptAgent,\n",
    "    # Vision-Language Model Agents\n",
    "    VLMAgent,\n",
    "    OpenAIVisionAgent,\n",
    "    AnthropicVisionAgent,\n",
    "    GoogleVisionAgent,\n",
    "    # Enum\n",
    "    Language,\n",
    "    OpenAIModel,\n",
    "    AnthropicModel,\n",
    "    GoogleModel,\n",
    "    OpenAITranscriptModel,\n",
    "    GoogleTranscriptModel,\n",
    "    OpenAIVisionModel,\n",
    "    AnthropicVisionModel,\n",
    "    GoogleVisionModel,\n",
    ")\n",
    "\n",
    "from typing import cast, Any\n",
    "from dotenv import load_dotenv\n",
    "from mimetypes import guess_type\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a27ec77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello các bạn, mình là Hùng.\n"
     ]
    }
   ],
   "source": [
    "class AudioAgent:\n",
    "    def __init__(self, audio_agent: AudioToTextAgent):\n",
    "        self.audio_agent = audio_agent\n",
    "\n",
    "    def transcribe(self, audio_input: bytes, mime_type: str = \"audio/mp3\") -> str:\n",
    "        return self.audio_agent.transcribe(audio_input=audio_input, mime_type=mime_type)\n",
    "\n",
    "\n",
    "# Initialize the audio agent with OpenAI's transcription capabilities\n",
    "\n",
    "openai_transcription_agent = OpenAITranscriptAgent(\n",
    "    model_name=OpenAITranscriptModel.GPT_4O_TRANSCRIBE,\n",
    "    prompt=\"You are listening to a doctor/doctors taking patient's history.\",\n",
    "    language=Language.VI_VN,  # Default to Vietnamese\n",
    ")\n",
    "\n",
    "google_transcription_agent = GoogleTranscriptAgent(\n",
    "    model_name=GoogleTranscriptModel.GEMINI_2_5_PRO_PREVIEW,\n",
    "    prompt=\"You are listening to a doctor/doctors taking patient's history.\",\n",
    "    language=Language.VI_VN,  # Default to Vietnamese\n",
    ")\n",
    "\n",
    "audio_agent = AudioAgent(audio_agent=google_transcription_agent)\n",
    "\n",
    "# Usage example:\n",
    "audio_file_path = \"tests\\\\audio_test.m4a\"  # Replace with your audio file path\n",
    "audio_bytes = open(audio_file_path, \"rb\").read()\n",
    "transcript = audio_agent.transcribe(\n",
    "    audio_input=audio_bytes, mime_type=guess_type(audio_file_path)[0] or \"audio/mp3\"\n",
    ")\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a037e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientNote(BaseModel):\n",
    "    patient_name: str\n",
    "    age: int\n",
    "    current_signs_and_symptom: str\n",
    "    previous_medical_history: str\n",
    "    current_medication: str\n",
    "    \n",
    "    concerns: list[str]\n",
    "    \n",
    "\n",
    "\n",
    "class VisionAgent:\n",
    "    def __init__(self, vision_agent: VLMAgent):\n",
    "        self.vision_agent = vision_agent\n",
    "\n",
    "    def analyze(\n",
    "        self,\n",
    "        images: list[bytes],\n",
    "        input_text: str = \"\",\n",
    "        images_mime_type: list[str] | str = \"image/png\",\n",
    "    ) -> dict:\n",
    "        result: dict[str, Any] = cast(\n",
    "            dict[str, Any],\n",
    "            self.vision_agent.analyze_images(\n",
    "                images=images,\n",
    "                input_text=input_text,\n",
    "                output_format=PatientNote,\n",
    "                images_mime_type=images_mime_type,\n",
    "            ),\n",
    "        )\n",
    "        return result\n",
    "\n",
    "\n",
    "# Initialize the vision agent with OpenAI's vision capabilities\n",
    "openai_vision_agent = OpenAIVisionAgent(\n",
    "    model_name=OpenAIVisionModel.GPT_4_1,\n",
    "    prompt=\"You are a medical assistant listening to a doctor's interview with a patient and reviewing their medical records. Summarize the patient's information for the electronic health record. If there are discrepancies, use your best judgment to fill in gaps and raise any concerns for the doctor.\",\n",
    "    language=Language.VI_VN,  # Default to Vietnamese\n",
    ")\n",
    "\n",
    "google_vision_agent = GoogleVisionAgent(\n",
    "    model_name=GoogleVisionModel.GEMINI_2_5_PRO_PREVIEW,\n",
    "    prompt=\"You are a medical assistant listening to a doctor's interview with a patient and reviewing their medical records. Summarize the patient's information for the electronic health record. If there are discrepancies, use your best judgment to fill in gaps and raise any concerns for the doctor.\",\n",
    "    language=Language.VI_VN,  # Default to Vietnamese\n",
    ")\n",
    "\n",
    "anthropic_vision_agent = AnthropicVisionAgent(\n",
    "    model_name=AnthropicVisionModel.CLAUDE_SONNET_4,\n",
    "    prompt=\"You are a medical assistant listening to a doctor's interview with a patient and reviewing their medical records. Summarize the patient's information for the electronic health record. If there are discrepancies, use your best judgment to fill in gaps and raise any concerns for the doctor.\",\n",
    "    language=Language.VI_VN,  # Default to Vietnamese\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c75066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcript the converssation\n",
    "audio_file_path = \"data\\\\0.cvh-stemi\\\\cvh.m4a\"\n",
    "audio_bytes = open(audio_file_path, \"rb\").read()\n",
    "first_transcript = audio_agent.transcribe(\n",
    "    audio_input=audio_bytes, mime_type=guess_type(audio_file_path)[0] or \"audio/mp3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "356ad55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dạ. Anh làm gì ý nhỉ?\\n- Tim mạch.\\n- Tim mạch là sao nhỉ? Anh lấy thuốc cho ông à?\\n- Vâng ạ.\\n- Bảo ông vào đây đi, em không nhớ ông đâu. Bảo ông vào đây.\\n- Ông khám bây giờ đây rồi.\\nSáng nay ông đi khám về làm sao đây ông?\\n- Khám chiều.\\n- Ông khám chiều nay à? Đơn thuốc cũ của ông đâu ấy nhỉ?\\n- Đây.\\n- Có đấy.\\n- Đơn ông phải cầm chứ?\\n- Có.\\n- Đơn thuốc cũ.\\n- Đơn thuốc cũ ở đâu đấy?\\n- Đây ạ.\\nTrước ông có đặt stent không?\\n- Không đặt được.\\n- Nhồi máu cơ tim mà muộn quá không đặt được stent đúng không?\\n- Vâng ạ.\\n- Ok.\\n- Có hút thuốc không?\\n- Ông bị tiểu đường nữa nhỉ?\\n- Tiểu đường.\\n- Ừ.\\nĐể cháu kê đơn cho ông nhá. Tháng này các xét nghiệm của ông thì cháu thấy tốt thôi. Nhưng đường máu vẫn hơi cao, đường máu này là sau ăn thì nó hơi cao tí chấp nhận được. Ông có suy thận một tí, ông có biết không?\\n- Không.\\n- Ông suy thận khoảng độ một, độ một thôi nhá. Độ một chấm, độ hai gì đấy. Cái thứ hai là ông có... nhồi máu cơ tim thì ông vẫn phải dùng thuốc chống đông nhá, không bỏ được đâu nhá.\\n- Vâng.\\n- Không bỏ là là tèo đấy. Chức năng tim thì hiện tại bảo tồn, người ta gọi là suy tim mức độ nhẹ thôi nhá.\\nThế thì bây giờ của ông sẽ có... Ông bảo hiểm nhỉ?\\n- Vâng ạ.\\nLoại nào cháu kê bảo hiểm, ông có lấy bảo hiểm, loại nào kê ngoài ông mua ngoài cho cháu nhá.\\n- Vâng.\\nBây giờ nhịp tim của ông khoảng bao nhiêu?\\n- Cũng không nắm được.\\n- Huyết áp của ông bây giờ khoảng bao nhiêu?\\n- Huyết áp 130, 120.\\n- 130, 120 à?\\nMỡ máu của ông vẫn còn hơi cao nhẹ tí, thôi cũng được. So với tháng trước là chức năng tim ông tháng này tốt hơn đấy. Tốt hơn ngày xưa.\\n- Bây giờ có đặt được không ạ?\\n- Không, muộn rồi không đặt được. Đặt cũng không đặt ra vấn đề đặt làm gì.\\n- Tám thuốc nhỉ. Tám thuốc thì đây được à... Một thuốc phải mua này, hai thuốc phải mua này, ba thuốc...\\n- Ở nhà ông hay thử tiểu đường không? Đường máu của ông khoảng bao nhiêu?\\n- Đường máu, đường máu khoảng bao nhiêu?\\n- Khoảng bao nhiêu ạ?\\n- Ông không thử à?\\n- Có, có thử nhưng mà...\\n- Khoảng bao nhiêu thôi?\\n- Cái gì, cái gì ạ?\\n- Đường máu ở nhà ông bình thường ông hay thử khoảng bao nhiêu? Tại vì đường máu đây là sau ăn thôi nên là 11 cũng là hơi cao. Thì đường máu bình thường ở nhà ông hay kiểm tra là khoảng bao nhiêu chị nhỉ?\\n- Không rõ được thì thỉnh thoảng cái ông này.\\n- Cũng oái oăm quá nhỉ. Ông có có có có ấy không nhỉ, có cái máy kiểm tra tiểu đường không?\\n- Đường máu đây là test tiểu đường phải không ạ?\\n- Vâng, test tiểu đường đấy.\\n- Vâng vâng để em hỏi.\\n- 7.5 mấy trong á.\\n- 7.5 đấy hả?\\n- Đúng rồi.\\n- Cũng hơi cao.\\n- Cái chống đông của ông này chịu khó dùng khoảng ba tháng nhá. Sau đó ổn thì bọn em chuyển sang thuốc bảo hiểm, tại vì mấy tháng đầu nó quan trọng. Can thiệp bây giờ thì không đặt ra vấn đề nữa, tại vì mình làm nó chỉ có tốn tiền thôi. Có điều là bây giờ mình sẽ nâng chức năng tim lên bằng cái, bằng thuốc nhé.\\n- Vâng.\\n- Đây thuốc tự túc này. Thuốc bảo hiểm này.\\n- Thôi giấy hẹn tái khám lại.\\n- Rồi, về đi ạ. Xong nhá.\\n- Vâng, vâng cảm ơn bác.\\n- Vâng, vâng.\\n- Cái ca người quen em ngày xưa bà mổ cái cột sống ổn không?\\n- Dạ?\\n- Ổn không?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c3e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_transcript = \"Dạ. Anh làm gì ý nhỉ?\\n- Tim mạch.\\n- Tim mạch là sao nhỉ? Anh lấy thuốc cho ông à?\\n- Vâng ạ.\\n- Bảo ông vào đây đi, em không nhớ ông đâu. Bảo ông vào đây.\\n- Ông khám bây giờ đây rồi.\\nSáng nay ông đi khám về làm sao đây ông?\\n- Khám chiều.\\n- Ông khám chiều nay à? Đơn thuốc cũ của ông đâu ấy nhỉ?\\n- Đây.\\n- Có đấy.\\n- Đơn ông phải cầm chứ?\\n- Có.\\n- Đơn thuốc cũ.\\n- Đơn thuốc cũ ở đâu đấy?\\n- Đây ạ.\\nTrước ông có đặt stent không?\\n- Không đặt được.\\n- Nhồi máu cơ tim mà muộn quá không đặt được stent đúng không?\\n- Vâng ạ.\\n- Ok.\\n- Có hút thuốc không?\\n- Ông bị tiểu đường nữa nhỉ?\\n- Tiểu đường.\\n- Ừ.\\nĐể cháu kê đơn cho ông nhá. Tháng này các xét nghiệm của ông thì cháu thấy tốt thôi. Nhưng đường máu vẫn hơi cao, đường máu này là sau ăn thì nó hơi cao tí chấp nhận được. Ông có suy thận một tí, ông có biết không?\\n- Không.\\n- Ông suy thận khoảng độ một, độ một thôi nhá. Độ một chấm, độ hai gì đấy. Cái thứ hai là ông có... nhồi máu cơ tim thì ông vẫn phải dùng thuốc chống đông nhá, không bỏ được đâu nhá.\\n- Vâng.\\n- Không bỏ là là tèo đấy. Chức năng tim thì hiện tại bảo tồn, người ta gọi là suy tim mức độ nhẹ thôi nhá.\\nThế thì bây giờ của ông sẽ có... Ông bảo hiểm nhỉ?\\n- Vâng ạ.\\nLoại nào cháu kê bảo hiểm, ông có lấy bảo hiểm, loại nào kê ngoài ông mua ngoài cho cháu nhá.\\n- Vâng.\\nBây giờ nhịp tim của ông khoảng bao nhiêu?\\n- Cũng không nắm được.\\n- Huyết áp của ông bây giờ khoảng bao nhiêu?\\n- Huyết áp 130, 120.\\n- 130, 120 à?\\nMỡ máu của ông vẫn còn hơi cao nhẹ tí, thôi cũng được. So với tháng trước là chức năng tim ông tháng này tốt hơn đấy. Tốt hơn ngày xưa.\\n- Bây giờ có đặt được không ạ?\\n- Không, muộn rồi không đặt được. Đặt cũng không đặt ra vấn đề đặt làm gì.\\n- Tám thuốc nhỉ. Tám thuốc thì đây được à... Một thuốc phải mua này, hai thuốc phải mua này, ba thuốc...\\n- Ở nhà ông hay thử tiểu đường không? Đường máu của ông khoảng bao nhiêu?\\n- Đường máu, đường máu khoảng bao nhiêu?\\n- Khoảng bao nhiêu ạ?\\n- Ông không thử à?\\n- Có, có thử nhưng mà...\\n- Khoảng bao nhiêu thôi?\\n- Cái gì, cái gì ạ?\\n- Đường máu ở nhà ông bình thường ông hay thử khoảng bao nhiêu? Tại vì đường máu đây là sau ăn thôi nên là 11 cũng là hơi cao. Thì đường máu bình thường ở nhà ông hay kiểm tra là khoảng bao nhiêu chị nhỉ?\\n- Không rõ được thì thỉnh thoảng cái ông này.\\n- Cũng oái oăm quá nhỉ. Ông có có có có ấy không nhỉ, có cái máy kiểm tra tiểu đường không?\\n- Đường máu đây là test tiểu đường phải không ạ?\\n- Vâng, test tiểu đường đấy.\\n- Vâng vâng để em hỏi.\\n- 7.5 mấy trong á.\\n- 7.5 đấy hả?\\n- Đúng rồi.\\n- Cũng hơi cao.\\n- Cái chống đông của ông này chịu khó dùng khoảng ba tháng nhá. Sau đó ổn thì bọn em chuyển sang thuốc bảo hiểm, tại vì mấy tháng đầu nó quan trọng. Can thiệp bây giờ thì không đặt ra vấn đề nữa, tại vì mình làm nó chỉ có tốn tiền thôi. Có điều là bây giờ mình sẽ nâng chức năng tim lên bằng cái, bằng thuốc nhé.\\n- Vâng.\\n- Đây thuốc tự túc này. Thuốc bảo hiểm này.\\n- Thôi giấy hẹn tái khám lại.\\n- Rồi, về đi ạ. Xong nhá.\\n- Vâng, vâng cảm ơn bác.\\n- Vâng, vâng.\\n- Cái ca người quen em ngày xưa bà mổ cái cột sống ổn không?\\n- Dạ?\\n- Ổn không?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47122261",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     15\u001b[39m image_file_paths = get_all_image_files_in_folder(data_folder)\n\u001b[32m     17\u001b[39m vision_agent = VisionAgent(vision_agent=google_vision_agent)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m ehr = \u001b[43mvision_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage_file_paths\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfirst_transcript\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages_mime_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mguess_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimage/jpg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage_file_paths\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mVisionAgent.analyze\u001b[39m\u001b[34m(self, images, input_text, images_mime_type)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34manalyze\u001b[39m(\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     16\u001b[39m     images: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[32m     17\u001b[39m     input_text: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m     images_mime_type: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mimage/png\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m     20\u001b[39m     result: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = cast(\n\u001b[32m     21\u001b[39m         \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvision_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43manalyze_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m            \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPatientNote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m            \u001b[49m\u001b[43mimages_mime_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages_mime_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     28\u001b[39m     )\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Github\\5_0_felineco_medical_assistant\\felineco-ai-python\\src\\ai_python_services\\ai_agents\\vlm_agents.py:289\u001b[39m, in \u001b[36mGoogleVisionAgent.analyze_images\u001b[39m\u001b[34m(self, images, input_text, output_format, images_mime_type)\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.text \u001b[38;5;28;01mif\u001b[39;00m response.text \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    288\u001b[39m     \u001b[38;5;66;03m# JSON output using Google's structured output\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_mime_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_schema\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    297\u001b[39m     \u001b[38;5;66;03m# Fallback to text parsing if parsed is empty/null\u001b[39;00m\n\u001b[32m    298\u001b[39m     response_text = response.text \u001b[38;5;28;01mif\u001b[39;00m response.text \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\5_0_felineco_medical_assistant\\felineco-ai-python\\.venv\\Lib\\site-packages\\google\\genai\\models.py:5977\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5975\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc > \u001b[32m0\u001b[39m:\n\u001b[32m   5976\u001b[39m   i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5977\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5978\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5979\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5980\u001b[39m   logger.info(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAFC remote call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is done.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   5981\u001b[39m   remaining_remote_calls_afc -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\5_0_felineco_medical_assistant\\felineco-ai-python\\.venv\\Lib\\site-packages\\google\\genai\\models.py:4940\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   4937\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m   4938\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m4940\u001b[39m response_dict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4941\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   4942\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4944\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_client.vertexai:\n\u001b[32m   4945\u001b[39m   response_dict = _GenerateContentResponse_from_vertex(\n\u001b[32m   4946\u001b[39m       \u001b[38;5;28mself\u001b[39m._api_client, response_dict\n\u001b[32m   4947\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\5_0_felineco_medical_assistant\\felineco-ai-python\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:785\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m    776\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    777\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    780\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    781\u001b[39m ) -> Union[BaseResponse, Any]:\n\u001b[32m    782\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m    783\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m    784\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m785\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m   json_response = response.json\n\u001b[32m    787\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m json_response:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\5_0_felineco_medical_assistant\\felineco-ai-python\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:707\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m    703\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m    704\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m    705\u001b[39m   )\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_httpx_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m      \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m      \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    714\u001b[39m   errors.APIError.raise_for_response(response)\n\u001b[32m    715\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m    716\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m    717\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\5_0_felineco_medical_assistant\\felineco-ai-python\\.venv\\Lib\\site-packages\\httpx\\_client.py:825\u001b[39m, in \u001b[36mClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    810\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m    812\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    813\u001b[39m     method=method,\n\u001b[32m    814\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    823\u001b[39m     extensions=extensions,\n\u001b[32m    824\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\5_0_felineco_medical_assistant\\felineco-ai-python\\.venv\\Lib\\site-packages\\httpx\\_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\5_0_felineco_medical_assistant\\felineco-ai-python\\.venv\\Lib\\site-packages\\httpx\\_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\5_0_felineco_medical_assistant\\felineco-ai-python\\.venv\\Lib\\site-packages\\httpx\\_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\5_0_felineco_medical_assistant\\felineco-ai-python\\.venv\\Lib\\site-packages\\httpx\\_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\5_0_felineco_medical_assistant\\felineco-ai-python\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\5_0_felineco_medical_assistant\\felineco-ai-python\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\5_0_felineco_medical_assistant\\felineco-ai-python\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\5_0_felineco_medical_assistant\\felineco-ai-python\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\5_0_felineco_medical_assistant\\felineco-ai-python\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\5_0_felineco_medical_assistant\\felineco-ai-python\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:88\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     86\u001b[39m         \u001b[38;5;28mself\u001b[39m._send_request_headers(**kwargs)\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33msend_request_body\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_request_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m WriteError:\n\u001b[32m     90\u001b[39m     \u001b[38;5;66;03m# If we get a write error while we're writing the request,\u001b[39;00m\n\u001b[32m     91\u001b[39m     \u001b[38;5;66;03m# then we supress this error and move on to attempting to\u001b[39;00m\n\u001b[32m     92\u001b[39m     \u001b[38;5;66;03m# read the response. Servers can sometimes close the request\u001b[39;00m\n\u001b[32m     93\u001b[39m     \u001b[38;5;66;03m# pre-emptively and then respond with a well formed HTTP\u001b[39;00m\n\u001b[32m     94\u001b[39m     \u001b[38;5;66;03m# error response.\u001b[39;00m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\5_0_felineco_medical_assistant\\felineco-ai-python\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:159\u001b[39m, in \u001b[36mHTTP11Connection._send_request_body\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m request.stream:\n\u001b[32m    158\u001b[39m     event = h11.Data(data=chunk)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28mself\u001b[39m._send_event(h11.EndOfMessage(), timeout=timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\5_0_felineco_medical_assistant\\felineco-ai-python\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:166\u001b[39m, in \u001b[36mHTTP11Connection._send_event\u001b[39m\u001b[34m(self, event, timeout)\u001b[39m\n\u001b[32m    164\u001b[39m bytes_to_send = \u001b[38;5;28mself\u001b[39m._h11_state.send(event)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bytes_to_send \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_to_send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\5_0_felineco_medical_assistant\\felineco-ai-python\\.venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py:138\u001b[39m, in \u001b[36mSyncStream.write\u001b[39m\u001b[34m(self, buffer, timeout)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m buffer:\n\u001b[32m    137\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     n = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m     buffer = buffer[n:]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.11.13-windows-x86_64-none\\Lib\\ssl.py:1242\u001b[39m, in \u001b[36mSSLSocket.send\u001b[39m\u001b[34m(self, data, flags)\u001b[39m\n\u001b[32m   1238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1239\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1240\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to send() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1241\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1244\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().send(data, flags)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "data_folder = \"data\\\\0.cvh-stemi\"\n",
    "\n",
    "# Define a list of image file extensions\n",
    "IMAGE_EXTENSIONS = {\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\", \".tiff\"}\n",
    "\n",
    "\n",
    "def get_all_image_files_in_folder(folder_path: str) -> list[str]:\n",
    "    return [\n",
    "        str(file)\n",
    "        for file in Path(folder_path).rglob(\"*\")\n",
    "        if file.is_file() and file.suffix.lower() in IMAGE_EXTENSIONS\n",
    "    ]\n",
    "\n",
    "\n",
    "image_file_paths = get_all_image_files_in_folder(data_folder)\n",
    "\n",
    "vision_agent = VisionAgent(vision_agent=google_vision_agent)\n",
    "\n",
    "ehr = vision_agent.analyze(\n",
    "    images=[open(image_path, \"rb\").read() for image_path in image_file_paths],\n",
    "    input_text=first_transcript,\n",
    "    images_mime_type=[\n",
    "        guess_type(image_path)[0] or \"image/jpg\" for image_path in image_file_paths\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ff14eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'patient_name': 'Cao Văn Hợp',\n",
       " 'age': 65,\n",
       " 'current_signs_and_symptom': 'Bệnh nhân tái khám để theo dõi bệnh tim mạch và lấy thuốc. Các chỉ số hiện tại: huyết áp 140/90 mmHg (theo hồ sơ), đường huyết sau ăn 11 mmol/L và tại nhà khoảng 7.5 mmol/L (hơi cao). Bác sĩ nhận định chức năng tim có cải thiện nhưng vẫn còn suy tim mức độ nhẹ và mỡ máu hơi cao.',\n",
       " 'previous_medical_history': 'Tiền sử nhồi máu cơ tim nhưng không đặt được stent do đến muộn. Ngoài ra còn có bệnh đái tháo đường, tăng huyết áp, và rối loạn lipid máu. Ghi nhận mới có suy thận mạn độ 1-2 mà bệnh nhân không biết.',\n",
       " 'current_medication': 'Đang theo dõi để nhận đơn thuốc mới. Bác sĩ nhấn mạnh tầm quan trọng của việc duy trì thuốc chống đông máu và sẽ kê đơn kết hợp thuốc bảo hiểm y tế và thuốc bệnh nhân tự túc mua ngoài để cải thiện chức năng tim.',\n",
       " 'concerns': [\"Có sự mâu thuẫn lớn trong hồ sơ: Hồ sơ bệnh án điện tử ghi 'Tiền sử bệnh: stent động mạch vành RCA tháng 1/2025', nhưng trong cuộc trao đổi, cả bác sĩ và bệnh nhân đều xác nhận là không đặt stent vì đến viện muộn. Cần xem xét và chỉnh sửa lại thông tin này trong hồ sơ.\",\n",
       "  'Bệnh nhân không hề biết về tình trạng suy thận độ 1-2 của mình. Cần tư vấn và giáo dục sức khỏe cho bệnh nhân về vấn đề này.',\n",
       "  'Chỉ số đường huyết của bệnh nhân vẫn còn ở mức cao, cho thấy việc kiểm soát đường huyết có thể chưa tối ưu.',\n",
       "  \"Bệnh nhân báo cáo huyết áp không rõ ràng ('130, 120'), cần dựa vào số đo chính xác tại phòng khám (140/90 mmHg) và theo dõi thêm.\"]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ehr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
